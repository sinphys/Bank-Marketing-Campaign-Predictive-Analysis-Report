{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b845d686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 2: Load the Dataset\n",
    "file_path = './data/bank.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee764da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clean and map target column\n",
    "data['deposit'] = data['deposit'].str.strip().str.lower()\n",
    "data['deposit'] = data['deposit'].map({'yes': 1, 'no': 0})\n",
    "\n",
    "print(\"Cleaned target values:\\n\", data['deposit'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba61496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Basic Info\n",
    "print(\"\\nDataset Info:\")\n",
    "print(data.info())\n",
    "print(\"\\nStatistical Summary:\")\n",
    "print(data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266eb9ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Encode Categorical Features (FIXED)\n",
    "categorical_cols = data.select_dtypes(include=['object']).columns\n",
    "data_encoded = pd.get_dummies(data, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912419bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Scale Numerical Features\n",
    "numerical_cols = ['age', 'balance', 'day', 'campaign', 'pdays', 'previous']\n",
    "scaler = StandardScaler()\n",
    "data_encoded[numerical_cols] = scaler.fit_transform(data_encoded[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e13afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Train-Test Split\n",
    "X = data_encoded.drop('deposit', axis=1)\n",
    "y = data_encoded['deposit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"\\nTrain/Test split completed.\")\n",
    "print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc6c31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Step 8: Initialize and fit the Logistic Regression model\n",
    "model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Predict on the test set using Logistic Regression\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Step 10: Evaluate Logistic Regression model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b890075",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=2000, solver='liblinear', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 11: Predict and evaluate with tuned Logistic Regression (liblinear)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(f\"\\nAccuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22801b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12: Cross-validation score for Logistic Regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"CV Accuracy: {scores.mean():.4f} ± {scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5c2d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13: Cross-validation score for Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')\n",
    "print(f\"Random Forest CV Accuracy: {rf_scores.mean():.4f} ± {rf_scores.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdde5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 14: Feature importance from Random Forest\n",
    "rf_model.fit(X_train, y_train)\n",
    "importances = pd.Series(rf_model.feature_importances_, index=X.columns)\n",
    "print(importances.sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95b0100",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data\n",
    "subscribed = 5289\n",
    "not_subscribed = 5873\n",
    "subscription_counts = pd.Series({\n",
    "    'Subscribed (1)': subscribed,\n",
    "    'Not Subscribed (0)': not_subscribed\n",
    "})\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "subscription_counts.plot(kind='bar', color=['green', 'red'])\n",
    "plt.title('Client Subscription Distribution')\n",
    "plt.ylabel('Number of Clients')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_subscription_distribution.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "sizes = [subscribed, not_subscribed]\n",
    "labels = ['Subscribed', 'Not Subscribed']\n",
    "colors = ['green', 'red']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.pie(sizes, labels=labels, autopct='%1.1f%%', colors=colors, startangle=140)\n",
    "plt.title('Subscription Percentage')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_subscription_pie.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "# Metrics\n",
    "model_accuracy = 0.8271\n",
    "precision_1 = 0.83\n",
    "recall_1 = 0.80\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.barplot(\n",
    "    x=['Accuracy', 'Precision (Subscribed)', 'Recall (Subscribed)'],\n",
    "    y=[model_accuracy, precision_1, recall_1],\n",
    "    palette='Blues_d'\n",
    ")\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Score')\n",
    "plt.title('Model Performance Metrics')\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"plot_model_metrics.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Assuming `data_encoded` is your processed dataset\n",
    "# and `deposit` is the binary target column\n",
    "\n",
    "# Step 15: Find correlation with target\n",
    "correlation = data_encoded.corr()['deposit'].drop('deposit').abs().sort_values(ascending=False)\n",
    "most_correlated_feature = correlation.idxmax()\n",
    "print(f\"Most correlated feature: {most_correlated_feature} (Correlation: {correlation.max():.4f})\")\n",
    "\n",
    "# Step 16: Prepare single-feature dataset\n",
    "X_single = data_encoded[[most_correlated_feature]]\n",
    "y = data_encoded['deposit']\n",
    "\n",
    "# Step 17: Train/Test split\n",
    "X_train_s, X_test_s, y_train_s, y_test_s = train_test_split(\n",
    "    X_single, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Step 18: Train logistic regression model\n",
    "single_feature_model = LogisticRegression(max_iter=1000)\n",
    "single_feature_model.fit(X_train_s, y_train_s)\n",
    "\n",
    "# Step 19: Evaluate model\n",
    "y_pred_s = single_feature_model.predict(X_test_s)\n",
    "accuracy_s = accuracy_score(y_test_s, y_pred_s)\n",
    "\n",
    "print(\"\\nSingle Feature Model Performance:\")\n",
    "print(f\"Feature Used: {most_correlated_feature}\")\n",
    "print(f\"Accuracy: {accuracy_s:.4f}\")\n",
    "print(classification_report(y_test_s, y_pred_s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_Kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
